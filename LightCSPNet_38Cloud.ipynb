{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0995befc",
   "metadata": {},
   "source": [
    "# LightCSPNet on 38-Cloud Dataset\n",
    "This notebook trains a basic CNN model for cloud segmentation using RGB input from the 38-Cloud dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ff543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31229f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for RGB input\n",
    "class CloudDatasetRGB(Dataset):\n",
    "    def __init__(self, red_dir, green_dir, blue_dir, mask_dir, transform=None):\n",
    "        self.red_dir = red_dir\n",
    "        self.green_dir = green_dir\n",
    "        self.blue_dir = blue_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.red_filenames = sorted(os.listdir(red_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.red_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        red_filename = self.red_filenames[idx]\n",
    "\n",
    "        # Extract patch identifier (after \"red_\")\n",
    "        patch_id = red_filename.replace(\"red_\", \"\")\n",
    "\n",
    "        # Construct green and blue filenames\n",
    "        green_filename = \"green_\" + patch_id\n",
    "        blue_filename = \"blue_\" + patch_id\n",
    "        mask_filename = \"gt_\" + patch_id\n",
    "\n",
    "        r = Image.open(os.path.join(self.red_dir, red_filename)).convert(\"L\")\n",
    "        g = Image.open(os.path.join(self.green_dir, green_filename)).convert(\"L\")\n",
    "        b = Image.open(os.path.join(self.blue_dir, blue_filename)).convert(\"L\")\n",
    "        rgb = Image.merge(\"RGB\", (r, g, b))\n",
    "\n",
    "        mask = Image.open(os.path.join(self.mask_dir, mask_filename)).convert(\"L\")\n",
    "        mask = np.array(mask)\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            rgb = self.transform(rgb)\n",
    "            mask = Image.fromarray(mask)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return rgb, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7418e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightCSPNet model\n",
    "class LightCSPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LightCSPNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.upsample = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = torch.relu(self.conv1(x))\n",
    "        x2 = self.pool(torch.relu(self.conv2(x1)))\n",
    "        x3 = self.pool(torch.relu(self.conv3(x2)))\n",
    "        x4 = self.upsample(torch.relu(self.conv4(x3)))\n",
    "        return torch.sigmoid(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf148a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice Coefficient\n",
    "def dice_coeff(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).float()\n",
    "    smooth = 1.0\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "423f8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(images)\n",
    "            dice = dice_coeff(outputs, masks)\n",
    "            dice_scores.append(dice.item())\n",
    "    return np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e605de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your dataset paths\n",
    "red_dir = \"38-Cloud_training/train_red\"\n",
    "green_dir = \"38-Cloud_training/train_green\"\n",
    "blue_dir = \"38-Cloud_training/train_blue\"\n",
    "mask_dir = \"38-Cloud_training/train_gt\"\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset and dataloader\n",
    "dataset = CloudDatasetRGB(red_dir, green_dir, blue_dir, mask_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a69b69f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6931, Dice Coeff: 0.0019\n",
      "Epoch 2, Loss: 0.6931, Dice Coeff: 0.0010\n",
      "Epoch 3, Loss: 0.6931, Dice Coeff: 0.0019\n",
      "Epoch 4, Loss: 0.6931, Dice Coeff: 0.0013\n",
      "Epoch 5, Loss: 0.6931, Dice Coeff: 0.0019\n",
      "Epoch 6, Loss: 0.6931, Dice Coeff: 0.0000\n",
      "Epoch 7, Loss: 0.6931, Dice Coeff: 0.0010\n",
      "Epoch 8, Loss: 0.6931, Dice Coeff: 0.0000\n",
      "Epoch 9, Loss: 0.6931, Dice Coeff: 0.0001\n",
      "Epoch 10, Loss: 0.6931, Dice Coeff: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and train\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LightCSPNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = train(model, dataloader, optimizer, criterion, device)\n",
    "    dice = evaluate(model, dataloader, device)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Dice Coeff: {dice:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
